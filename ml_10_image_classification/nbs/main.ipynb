{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "living-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python files\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/src\")\n",
    "\n",
    "import dataset\n",
    "import engine\n",
    "from model import get_alexnet, get_resnet, AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modern-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data_path = \"../data/\"\n",
    "df = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "# Get list of image files\n",
    "images = df.ImageId.values.tolist()\n",
    "images = [os.path.join(data_path, \"train_png\", i + \".png\") for i in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "awful-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.13666.15178752...</td>\n",
       "      <td>557374 2 1015 8 1009 14 1002 20 997 26 990 32 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.11028.15178752...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.10366.15178752...</td>\n",
       "      <td>514175 10 1008 29 994 30 993 32 991 33 990 34 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.10016.15178752...</td>\n",
       "      <td>592184 33 976 58 956 73 941 88 926 102 917 109...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.11444.15178752...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ImageId  \\\n",
       "0  1.2.276.0.7230010.3.1.4.8323329.13666.15178752...   \n",
       "1  1.2.276.0.7230010.3.1.4.8323329.11028.15178752...   \n",
       "2  1.2.276.0.7230010.3.1.4.8323329.10366.15178752...   \n",
       "3  1.2.276.0.7230010.3.1.4.8323329.10016.15178752...   \n",
       "4  1.2.276.0.7230010.3.1.4.8323329.11444.15178752...   \n",
       "\n",
       "                                       EncodedPixels  target  \n",
       "0  557374 2 1015 8 1009 14 1002 20 997 26 990 32 ...       1  \n",
       "1                                                 -1       0  \n",
       "2  514175 10 1008 29 994 30 993 32 991 33 990 34 ...       1  \n",
       "3  592184 33 976 58 956 73 941 88 926 102 917 109...       1  \n",
       "4                                                 -1       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "awful-deviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/train_png/1.2.276.0.7230010.3.1.4.8323329.13666.1517875247.117800.png',\n",
       " '../data/train_png/1.2.276.0.7230010.3.1.4.8323329.11028.1517875229.983789.png',\n",
       " '../data/train_png/1.2.276.0.7230010.3.1.4.8323329.10366.1517875223.393986.png',\n",
       " '../data/train_png/1.2.276.0.7230010.3.1.4.8323329.10016.1517875220.992175.png',\n",
       " '../data/train_png/1.2.276.0.7230010.3.1.4.8323329.11444.1517875232.977506.png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "confident-proposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
       "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (last_linear): Sequential(\n",
       "    (0): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.25, inplace=False)\n",
       "    (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device and epochs\n",
    "device = \"cuda\"\n",
    "epochs = 10\n",
    "\n",
    "targets =df.target.values\n",
    "# model = get_alexnet(pretrained=True)\n",
    "# model = get_resnet(pretrained=True)\n",
    "model = AlexNet()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "furnished-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image augmentation\n",
    "# mean and std of RGB channels\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "aug = albumentations.Compose(\n",
    "    [albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)]\n",
    ")\n",
    "# aug = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "widespread-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training and validation datasets\n",
    "train_images, valid_images, train_targets, valid_targets = train_test_split(\n",
    "    images, targets, stratify=targets, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = dataset.ClassificationDataset(\n",
    "    image_paths=train_images, targets=train_targets, \n",
    "    resize=(227, 227), augmentations=aug\n",
    ")\n",
    "valid_dataset = dataset.ClassificationDataset(\n",
    "    image_paths=train_images, targets=train_targets,\n",
    "    resize=(227, 227), augmentations=aug\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "medium-berkeley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list, dataset.ClassificationDataset)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images), type(valid_images), type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "optical-marble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/train_png/1.2.276.0.7230010.3.1.4.8323329.13152.1517875243.898511.png',\n",
       " '../data/train_png/1.2.276.0.7230010.3.1.4.8323329.1858.1517875169.946702.png',\n",
       " '../data/train_png/1.2.276.0.7230010.3.1.4.8323329.5369.1517875187.802444.png',\n",
       " '../data/train_png/1.2.276.0.7230010.3.1.4.8323329.12299.1517875238.450255.png',\n",
       " '../data/train_png/1.2.276.0.7230010.3.1.4.8323329.32482.1517875160.802571.png']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "suspended-pattern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 227, 227])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1][\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "statewide-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset[1]\n",
    "inputs = data[\"image\"]\n",
    "targets = data[\"targets\"]\n",
    "# Move data into device\n",
    "inputs = inputs.to(device, dtype=torch.float)\n",
    "targets = targets.to(device, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "spoken-forty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 227, 227]), torch.Size([]), tensor(0., device='cuda:0'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, targets.shape, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hybrid-shareware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "subject-blowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Valid AUC=0.5261574094094008\n",
      "Epoch=1, Valid AUC=0.5991361478797208\n",
      "Epoch=2, Valid AUC=0.6209951524533948\n",
      "Epoch=3, Valid AUC=0.6268789107938992\n",
      "Epoch=4, Valid AUC=0.6926146175223746\n",
      "Epoch=5, Valid AUC=0.6179618772819722\n",
      "Epoch=6, Valid AUC=0.7173027540061088\n",
      "Epoch=7, Valid AUC=0.6845520848198133\n",
      "Epoch=8, Valid AUC=0.7026812857025483\n",
      "Epoch=9, Valid AUC=0.6444200962013857\n"
     ]
    }
   ],
   "source": [
    "# Get data loader and training\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    engine.train(train_loader, model, optimizer, device)\n",
    "    preds, valid_targets = engine.evaluate(valid_loader, model, device)\n",
    "    auc = metrics.roc_auc_score(valid_targets, preds)\n",
    "    print(f\"Epoch={epoch}, Valid AUC={auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-listing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
